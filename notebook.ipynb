{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANS from DNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here, in general, is to find new valid equations that describe fluid flow. \n",
    "We will try to find new closures for the steady RANS equations based on direct numerical\n",
    "simulation (DNS) of a boundary layer.\n",
    "\n",
    "\n",
    "## Steady RANS equations\n",
    "\n",
    "$$\n",
    "(\\vec{U} \\cdot \\nabla) \\vec{U}\n",
    "+ \\frac{1}{\\rho} \\nabla P \n",
    "- \\nu \\nabla^2 \\vec{U}\n",
    "= - \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R},\n",
    "$$\n",
    "\n",
    "where in this case $\\mathbf{R}$ is the Reynolds stress tensor.\n",
    "\n",
    "In order to be rank-consistent, terms that \"make up\" \n",
    "$- \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R}$ can be one of:\n",
    "\n",
    "* Gradient of a scalar (e.g., pressure gradient)\n",
    "* Laplacian of a vector (e.g., viscous stress)\n",
    "* Inner product of a tensor with a vector\n",
    "* A vector multiplied by a scalar (e.g., advection)\n",
    "\n",
    "Some ideas for what the Reynolds stress residual term could be:\n",
    "\n",
    "$$\n",
    "- \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R} = \n",
    "      a \\nabla K \n",
    "    + b \\left( \\nabla \\vec{U} \\cdot \\nabla P \\right)\n",
    "$$\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "1. Pick terms (in addition to non-Reynolds stress Navier--Stokes terms).\n",
    "2. Create a random list of points in space that is at least as large as the number\n",
    "   of terms.\n",
    "3. At each point, acquire all data for all terms for all times.\n",
    "4. Average data at each point for all times.\n",
    "5. Solve for coefficients using a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import seaborn\n",
    "seaborn.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data from pyJHTDB\n",
    "\n",
    "1. Pick a bunch of points randomly throughout the domain, at least more than the number of terms we want to test.\n",
    "2. Add points in each direction for computing spatial derivatives.\n",
    "3. Get $\\vec{u}$, $p$, and their gradients for all time at all points in the list.\n",
    "4. Calculate terms based on mean values.\n",
    "5. Use a regression model to determine coefficients on each term.\n",
    "6. Repeat this process to ensure the coefficients don't change?\n",
    "7. Run a RANS simulation with this new model and check the results against the mean profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(\"data/jhtdb-transitional-bl/all-stats.h5\", key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check continuity\n",
    "div = df[\"dudx\"] + df[\"dvdy\"] + df[\"dwdz\"]\n",
    "div.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check above gives us an idea on how accurate these gradient calculations\n",
    "are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (\n",
    "    df.loc[df.index.get_level_values(\"x\")[-1000]]\n",
    "    .reset_index()\n",
    "    .plot(x=\"u\", y=\"y\", legend=False, ylabel=\"$U$\", xlabel=\"$y$\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the momentum equation\n",
    "from py_package import nu, rho\n",
    "\n",
    "momx_no_res = (\n",
    "    df.u * df.dudx\n",
    "    + df.v * df.dudy\n",
    "    + df.w * df.dudz\n",
    "    + (1 / rho) * df.dpdx\n",
    "    - nu * (df.d2udx2 + df.d2udy2 + df.d2udz2)\n",
    ")\n",
    "\n",
    "momx = momx_no_res + (df.duudx_fd + df.duvdy_fd)\n",
    "\n",
    "momx.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the $y$-component of the momentum equation\n",
    "\n",
    "$$\n",
    "U \\frac{\\partial V}{\\partial x}\n",
    "+ V \\frac{\\partial V}{\\partial y}\n",
    "= - \\frac{1}{\\rho} \\frac{\\partial P}{\\partial y}\n",
    "+ \\nu \\left( \n",
    "    \\frac{\\partial^2 V}{\\partial x^2}\n",
    "    + \\frac{\\partial^2 V}{\\partial y^2}\n",
    "    \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "- \\left(\n",
    "    \\frac{\\partial \\overline{u'v'}}{\\partial x}\n",
    "    + \\frac{\\partial \\overline{v'v'}}{\\partial y}\n",
    "    \\right\n",
    ")\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the y-component of the momentum equation\n",
    "from py_package import nu, rho\n",
    "\n",
    "momy_no_res = (\n",
    "    df.u * df.dvdx\n",
    "    + df.v * df.dvdy\n",
    "    + (1 / rho) * df.dpdy\n",
    "    - nu * (df.d2vdx2 + df.d2vdy2)\n",
    ")\n",
    "\n",
    "momy = momy_no_res + (df.duvdx_fd + df.duvdy_fd)\n",
    "\n",
    "momy_no_res.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momy_no_res.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how large the Reynold's stress residual is at different locations\n",
    "df1 = df.dropna().reset_index()\n",
    "df1.plot.scatter(\n",
    "    x=\"x\", y=\"y\", color=momy_no_res.dropna().values, cmap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute terms from averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the time-averaged profiles\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_profiles():\n",
    "    \"\"\"Read profile data from JHTDB HDF5 file, and assemble into a dictionary\n",
    "    of NumPy arrays.\n",
    "    \"\"\"\n",
    "    with h5py.File(\n",
    "        \"data/jhtdb-transitional-bl/time-ave-profiles.h5\", \"r\"\n",
    "    ) as f:\n",
    "        data = {}\n",
    "        for k in f.keys():\n",
    "            kn = k.split(\"_\")[0]\n",
    "            if kn.endswith(\"m\"):\n",
    "                kn = kn[:-1]\n",
    "            data[kn] = f[k][()]\n",
    "    # Calculate some finite difference gradients\n",
    "    dx = np.gradient(data[\"x\"])\n",
    "    dy = np.reshape(np.gradient(data[\"y\"]), (224, 1))\n",
    "    # dz = np.gradient(data[\"z\"])\n",
    "    # Correct fluctuation terms according to README\n",
    "    # >uum is the time-averaged of u*u (not u'*u', where u'=u-um).\n",
    "    # >So time-averaged of u'*u'=uum-um*um. Same for other quantities.\n",
    "    for dim1 in (\"u\", \"v\", \"w\"):\n",
    "        for dim2 in (\"u\", \"v\", \"w\"):\n",
    "            if f\"{dim1}{dim2}\" in data:\n",
    "                data[f\"{dim1}{dim2}\"] = (\n",
    "                    data[f\"{dim1}{dim2}\"] - data[dim1] * data[dim2]\n",
    "                )\n",
    "    # Correct the Reynolds stress terms\n",
    "\n",
    "    # Calculate gradients\n",
    "    data[\"dpdx\"] = np.gradient(data[\"p\"], axis=1) / dx\n",
    "    data[\"duudx\"] = np.gradient(data[\"uu\"], axis=1) / dx\n",
    "    data[\"duvdx\"] = np.gradient(data[\"uv\"], axis=1) / dx\n",
    "    data[\"duvdy\"] = np.gradient(data[\"uv\"], axis=0) / dy\n",
    "    data[\"dvvdy\"] = np.gradient(data[\"vv\"], axis=0) / dy\n",
    "    data[\"dudx\"] = np.gradient(data[\"u\"], axis=1) / dx\n",
    "    data[\"dudy\"] = np.gradient(data[\"u\"], axis=0) / dy\n",
    "    data[\"dvdx\"] = np.gradient(data[\"v\"], axis=1) / dx\n",
    "    data[\"dvdy\"] = np.gradient(data[\"v\"], axis=0) / dy\n",
    "    data[\"d2udx2\"] = np.gradient(data[\"dudx\"], axis=1) / dx\n",
    "    data[\"d2udy2\"] = np.gradient(data[\"dudy\"], axis=0) / dy\n",
    "    data[\"d2vdx2\"] = np.gradient(data[\"dvdx\"], axis=1) / dx\n",
    "    data[\"d2vdy2\"] = np.gradient(data[\"dvdy\"], axis=0) / dy\n",
    "    data[\"dpdx\"] = np.gradient(data[\"p\"], axis=1) / dx\n",
    "    data[\"dpdy\"] = np.gradient(data[\"p\"], axis=0) / dy\n",
    "    # data[\"dwdz\"] = np.gradient(data[\"w\"], axis=1) / dz\n",
    "    return data\n",
    "\n",
    "\n",
    "data = read_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RANS simulation versus averaged DNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"k-epsilon\"\n",
    "\n",
    "for ny in [15, 20, 30, 40, 60]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"laminar\"\n",
    "\n",
    "for ny in [40]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"new\"\n",
    "\n",
    "for ny in [40]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=-nu * data[\"d2udy2\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=1 / rho * data[\"dpdx\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=data[\"dudy\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=data[\"dudy\"][:, 1500]**(3)*data[\"y\"], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a bunch of quantities and add to the data\n",
    "data = read_profiles()\n",
    "dx = np.gradient(data[\"x\"])\n",
    "dy = np.reshape(np.gradient(data[\"y\"]), (224, 1))\n",
    "# Mean kinetic energy\n",
    "data[\"k\"] = 0.5 * (data[\"u\"] ** 2 + data[\"v\"] ** 2)\n",
    "# Squared gradients\n",
    "data[\"dudx2\"] = data[\"dudx\"] ** 2\n",
    "data[\"dudy2\"] = data[\"dudy\"] ** 2\n",
    "# Gradients of squares\n",
    "data[\"du2dy\"] = np.gradient(data[\"u\"] ** 2, axis=0) / dy\n",
    "data[\"dv2dy\"] = np.gradient(data[\"v\"] ** 2, axis=0) / dy\n",
    "data[\"du2dx\"] = np.gradient(data[\"u\"] ** 2, axis=1) / dx\n",
    "data[\"dv2dx\"] = np.gradient(data[\"v\"] ** 2, axis=1) / dx\n",
    "# Mean kinetic energy gradient\n",
    "data[\"dkdy\"] = np.gradient(data[\"k\"], axis=0) / dy\n",
    "data[\"dkdx\"] = np.gradient(data[\"k\"], axis=1) / dx\n",
    "data[\"d2kdy2\"] = np.gradient(data[\"dkdy\"], axis=0) / dy\n",
    "data[\"d2kdx2\"] = np.gradient(data[\"dkdx\"], axis=1) / dx\n",
    "# Gradients multiplied by each other\n",
    "# Gradients multiplied by mean values\n",
    "# Misc terms\n",
    "data[\"u2dudy\"] = data[\"u\"] ** 2 * data[\"dudy\"]\n",
    "data[\"udpdx\"] = data[\"u\"] * data[\"dpdx\"]\n",
    "data[\"dpdx2\"] = data[\"dpdx\"] ** 2\n",
    "data[\"dpdy2\"] = data[\"dpdy\"] ** 2\n",
    "data[\"d2pdx2\"] = np.gradient(data[\"dpdx\"], axis=1) / dx\n",
    "data[\"d2pdy2\"] = np.gradient(data[\"dpdy\"], axis=0) / dy\n",
    "data[\"dp2dx\"] = np.gradient(data[\"p\"] ** 2, axis=1) / dx\n",
    "data[\"dp2dy\"] = np.gradient(data[\"p\"] ** 2, axis=0) / dy\n",
    "data[\"vdpdy\"] = data[\"v\"] * data[\"dpdy\"]\n",
    "data[\"magsqrgradp\"] = data[\"dpdx\"] ** 2 + data[\"dpdy\"] ** 2\n",
    "data[\"laplacianp\"] = data[\"d2pdx2\"] + data[\"d2pdy2\"]\n",
    "data[\"laplacianu\"] = data[\"d2udx2\"] + data[\"d2udy2\"]\n",
    "data[\"laplacianv\"] = data[\"d2vdx2\"] + data[\"d2vdy2\"]\n",
    "data[\"vorticityz\"] = data[\"dvdx\"] - data[\"dudy\"]\n",
    "data[\"pu\"] = data[\"p\"] * data[\"u\"]\n",
    "data[\"pv\"] = data[\"p\"] * data[\"v\"]\n",
    "data[\"divvelpgrad_x\"] = data[\"u\"] * data[\"d2pdx2\"] + data[\"u\"] * data[\"d2pdy2\"]\n",
    "data[\"divvelpgrad_y\"] = data[\"v\"] * data[\"d2pdx2\"] + data[\"v\"] * data[\"d2pdy2\"]\n",
    "data[\"duvdy\"] = np.gradient(data[\"uv\"], axis=0) / dy\n",
    "data[\"duvdx\"] = np.gradient(data[\"uv\"], axis=1) / dx\n",
    "data[\"divuu_x\"] = data[\"du2dx\"] + data[\"duvdy\"]\n",
    "data[\"divuu_y\"] = data[\"duvdx\"] + data[\"dv2dy\"]\n",
    "data[\"magsqru\"] = data[\"u\"] ** 2 + data[\"v\"] ** 2\n",
    "data[\"pbymagsqru\"] = data[\"p\"] / data[\"magsqru\"]\n",
    "data[\"gradpbymagsqru_x\"] = np.gradient(data[\"pbymagsqru\"], axis=1) / dx\n",
    "data[\"gradpbymagsqru_y\"] = np.gradient(data[\"pbymagsqru\"], axis=0) / dy\n",
    "data[\"divp\"] = data[\"dpdx\"] + data[\"dpdy\"]\n",
    "data[\"ddivpdx\"] = np.gradient(data[\"divp\"], axis=1) / dx\n",
    "data[\"ddivpdy\"] = np.gradient(data[\"divp\"], axis=0) / dy\n",
    "data[\"gradugradpx\"] = data[\"dudx\"] * data[\"dpdx\"] + data[\"dudy\"] * data[\"dpdy\"]\n",
    "data[\"gradugradpy\"] = data[\"dvdx\"] * data[\"dpdx\"] + data[\"dvdy\"] * data[\"dpdy\"]\n",
    "# Reynolds stress terms\n",
    "data[\"restress_x\"] = data[\"duudx\"] + data[\"duvdy\"]\n",
    "data[\"restress_y\"] = data[\"duvdx\"] + data[\"dvvdy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "terms = [\n",
    "    # Mean kinetic energy gradients\n",
    "    \"dkdx\",\n",
    "    # \"dkdy\",\n",
    "    # Squared velocity gradients\n",
    "    # \"dudx2\",\n",
    "    # \"dudy2\",\n",
    "    # Gradients of squared velocity\n",
    "    # \"du2dx\",\n",
    "    # \"du2dy\",\n",
    "    # \"dv2dx\",\n",
    "    # \"dv2dy\",\n",
    "    # Cross-stream pressure gradient\n",
    "    # \"dpdy\",\n",
    "    # Misc\n",
    "    # \"u2dudy\",\n",
    "    # \"udpdx\",\n",
    "    \"dpdx2\",\n",
    "    \"dpdy2\",\n",
    "    \"d2pdx2\",\n",
    "    \"d2pdy2\",\n",
    "    # \"dp2dx\",\n",
    "    # \"dpdx\",\n",
    "]\n",
    "\n",
    "# Form our X matrix\n",
    "X = np.array([data[term].flatten() for term in terms]).transpose()\n",
    "\n",
    "# Form our y vector, which is simply the x-component of the 2-D RANS equations\n",
    "# with no Reynolds stresses\n",
    "y = (\n",
    "    data[\"u\"] * data[\"dudx\"]\n",
    "    + data[\"v\"] * data[\"dudy\"]\n",
    "    + 1 / rho * data[\"dpdx\"]\n",
    "    - nu * (data[\"d2udx2\"] + data[\"d2udy2\"])\n",
    ").flatten()\n",
    "\n",
    "print(\"Dataset size:\", len(y))\n",
    "\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "terms = [\n",
    "    # Mean kinetic energy gradients\n",
    "    # \"dkdx\",\n",
    "    \"dkdy\",\n",
    "    # Squared velocity gradients\n",
    "    # \"dudx2\",\n",
    "    # \"dudy2\",\n",
    "    # Gradients of squared velocity\n",
    "    # \"du2dx\",\n",
    "    # \"du2dy\",\n",
    "    # \"dv2dx\",\n",
    "    # \"dv2dy\",\n",
    "    # Streamwise pressure gradient\n",
    "    # \"dpdx\",\n",
    "    # Misc\n",
    "    # \"u2dudy\",\n",
    "    # \"udpdx\",\n",
    "    \"dpdx2\",\n",
    "    \"dpdy2\",\n",
    "    # \"d2pdx2\",\n",
    "    \"d2pdx2\",\n",
    "    \"d2pdy2\",\n",
    "    # \"dp2dx\",\n",
    "    # \"dpdy\",\n",
    "]\n",
    "\n",
    "# Form our X matrix\n",
    "X = np.array([data[term].flatten() for term in terms]).transpose()\n",
    "\n",
    "# Form our y vector, which is simply the x-component of the 2-D RANS equations\n",
    "# with no Reynolds stresses\n",
    "y = (\n",
    "    data[\"u\"] * data[\"dvdx\"]\n",
    "    + data[\"v\"] * data[\"dvdy\"]\n",
    "    + 1 / rho * data[\"dpdy\"]\n",
    "    - nu * (data[\"d2vdx2\"] + data[\"d2vdy2\"])\n",
    ").flatten()\n",
    "print(\"Dataset size:\", len(y))\n",
    "\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to solve for both components at the same time so we use the same\n",
    "# parameters for each\n",
    "terms = [\n",
    "    \"dkd{dim}\",\n",
    "    \"gradugradp{dim}\",\n",
    "    \"restress_{dim}\",  # Should be the most important terms\n",
    "    # \"divuu_{dim}\",\n",
    "    # \"divvelpgrad_{dim}\",\n",
    "    # \"ddivpd{dim}\",\n",
    "    # \"gradpbymagsqru_{dim}\",\n",
    "    # \"dpd{dim}\",  # Cheating\n",
    "]\n",
    "xterms = [t.format(dim=\"x\") for t in terms]\n",
    "yterms = [t.format(dim=\"y\") for t in terms]\n",
    "\n",
    "# Slice out \"non-important\" parts of the flow to not train on those\n",
    "# Basically that means stay near the wall and away from the inlet\n",
    "ix_min = 600\n",
    "iy_max = 100\n",
    "\n",
    "# Form our X matrix\n",
    "xx = np.array([data[term].flatten() for term in xterms]).transpose()\n",
    "xy = np.array([data[term].flatten() for term in yterms]).transpose()\n",
    "X = np.concatenate([xx, xy])\n",
    "xx_slice = np.array(\n",
    "    [data[term][:iy_max, ix_min:].flatten() for term in xterms]\n",
    ").transpose()\n",
    "xy_slice = np.array(\n",
    "    [data[term][:iy_max, ix_min:].flatten() for term in yterms]\n",
    ").transpose()\n",
    "X_slice = np.concatenate([xx_slice, xy_slice])\n",
    "\n",
    "xtarget = (\n",
    "    data[\"u\"] * data[\"dudx\"]\n",
    "    + data[\"v\"] * data[\"dudy\"]\n",
    "    + 1 / rho * data[\"dpdx\"]\n",
    "    - nu * (data[\"d2udx2\"] + data[\"d2udy2\"])\n",
    ")\n",
    "ytarget = (\n",
    "    data[\"u\"] * data[\"dvdx\"]\n",
    "    + data[\"v\"] * data[\"dvdy\"]\n",
    "    + 1 / rho * data[\"dpdy\"]\n",
    "    - nu * (data[\"d2vdx2\"] + data[\"d2vdy2\"])\n",
    ")\n",
    "\n",
    "# Our y vector is both of these appended to each other\n",
    "y = np.concatenate([xtarget.flatten(), ytarget.flatten()])\n",
    "y_slice = np.concatenate(\n",
    "    [xtarget[:iy_max, ix_min:].flatten(), ytarget[:iy_max, ix_min:].flatten()]\n",
    ")\n",
    "print(\"Dataset size:\", len(y_slice))\n",
    "\n",
    "# Fit the model\n",
    "reg = LinearRegression(fit_intercept=False).fit(X_slice, y_slice)\n",
    "\n",
    "# Compute the RMSE of the fit\n",
    "rmse_no_model = np.sqrt(np.sum(y**2))\n",
    "pred = reg.predict(X)\n",
    "error = y - pred\n",
    "rmse_model = np.sqrt(np.sum(error**2))\n",
    "error_x = error[: len(error) // 2].reshape((len(data[\"y\"]), len(data[\"x\"])))\n",
    "error_y = error[len(error) // 2:].reshape((len(data[\"y\"]), len(data[\"x\"])))\n",
    "\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print(\"RMSE no model:\", rmse_no_model)\n",
    "print(\"RMSE model:\", rmse_model)\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the distribution of errors coming from the model\n",
    "from py_package.plotting import plot_heatmap\n",
    "\n",
    "plot_heatmap(xtarget, data, ix_min=600, iy_max=100, diverging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    -data[\"restress_x\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "magtarget = np.sqrt(xtarget**2 + ytarget**2)\n",
    "\n",
    "fig = (\n",
    "    px.line(x=magtarget[:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=ytarget[:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=data[\"dvdx\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=xtarget[:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Reynolds stress residual as a target for an ML model\n",
    "# Solve a linear regression for the coefficients of all derived terms\n",
    "# Throw out terms with coefficients below a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write as a RANS model for OpenFOAM and solve this same problem there\n",
    "# First run a baseline case with a high Re kOmegaSST model\n",
    "# How to handle wall functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check mean flow from OpenFOAM simulation matches DNS"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "bl-turb-mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
