{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANS from DNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here, in general, is to find new valid equations that describe fluid flow. \n",
    "We will try to find new closures for the steady RANS equations based on direct numerical\n",
    "simulation (DNS) of a boundary layer.\n",
    "\n",
    "\n",
    "## Steady RANS equations\n",
    "\n",
    "$$\n",
    "(\\vec{U} \\cdot \\nabla) \\vec{U}\n",
    "+ \\frac{1}{\\rho} \\nabla P \n",
    "- \\nu \\nabla^2 \\vec{U}\n",
    "= - \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R},\n",
    "$$\n",
    "\n",
    "where in this case $\\mathbf{R}$ is the Reynolds stress tensor.\n",
    "\n",
    "In order to be rank-consistent, terms that \"make up\" \n",
    "$- \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R}$ can be one of:\n",
    "\n",
    "* Gradient of a scalar (e.g., pressure gradient)\n",
    "* Laplacian of a vector (e.g., viscous stress)\n",
    "* Inner product of a tensor with a vector\n",
    "* A vector multiplied by a scalar (e.g., advection)\n",
    "\n",
    "Some ideas for what the Reynolds stress residual term could be:\n",
    "\n",
    "$$\n",
    "- \\frac{1}{\\rho} \\nabla \\cdot \\mathbf{R} = \n",
    "      a \\nabla K \n",
    "    + b \\left( \\nabla \\vec{U} \\cdot \\nabla P \\right)\n",
    "    + c \\nabla \\cdot \\vec{U} \\nabla P\n",
    "$$\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "1. Pick terms (in addition to non-Reynolds stress Navier--Stokes terms).\n",
    "2. Create a random list of points in space that is at least as large as the number\n",
    "   of terms.\n",
    "3. At each point, acquire all data for all terms for all times.\n",
    "4. Average data at each point for all times.\n",
    "5. Solve for coefficients using a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import seaborn\n",
    "seaborn.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data from pyJHTDB\n",
    "\n",
    "1. Pick a bunch of points randomly throughout the domain, at least more than the number of terms we want to test.\n",
    "2. Add points in each direction for computing spatial derivatives.\n",
    "3. Get $\\vec{u}$, $p$, and their gradients for all time at all points in the list.\n",
    "4. Calculate terms based on mean values.\n",
    "5. Use a regression model to determine coefficients on each term.\n",
    "6. Repeat this process to ensure the coefficients don't change?\n",
    "7. Run a RANS simulation with this new model and check the results against the mean profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(\"data/jhtdb-transitional-bl/all-stats.h5\", key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check continuity\n",
    "div = df[\"dudx\"] + df[\"dvdy\"] + df[\"dwdz\"]\n",
    "div.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check above gives us an idea on how accurate these gradient calculations\n",
    "are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (\n",
    "    df.loc[df.index.get_level_values(\"x\")[-1000]]\n",
    "    .reset_index()\n",
    "    .plot(x=\"u\", y=\"y\", legend=False, ylabel=\"$U$\", xlabel=\"$y$\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the momentum equation\n",
    "from py_package import nu, rho\n",
    "\n",
    "momx_no_res = (\n",
    "    df.u * df.dudx\n",
    "    + df.v * df.dudy\n",
    "    + df.w * df.dudz\n",
    "    + (1 / rho) * df.dpdx\n",
    "    - nu * (df.d2udx2 + df.d2udy2 + df.d2udz2)\n",
    ")\n",
    "\n",
    "momx = momx_no_res + (df.duudx_fd + df.duvdy_fd)\n",
    "\n",
    "momx.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the $y$-component of the momentum equation\n",
    "\n",
    "$$\n",
    "U \\frac{\\partial V}{\\partial x}\n",
    "+ V \\frac{\\partial V}{\\partial y}\n",
    "= - \\frac{1}{\\rho} \\frac{\\partial P}{\\partial y}\n",
    "+ \\nu \\left( \n",
    "    \\frac{\\partial^2 V}{\\partial x^2}\n",
    "    + \\frac{\\partial^2 V}{\\partial y^2}\n",
    "    \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "- \\left(\n",
    "    \\frac{\\partial \\overline{u'v'}}{\\partial x}\n",
    "    + \\frac{\\partial \\overline{v'v'}}{\\partial y}\n",
    "    \\right\n",
    ")\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the y-component of the momentum equation\n",
    "from py_package import nu, rho\n",
    "\n",
    "momy_no_res = (\n",
    "    df.u * df.dvdx\n",
    "    + df.v * df.dvdy\n",
    "    + (1 / rho) * df.dpdy\n",
    "    - nu * (df.d2vdx2 + df.d2vdy2)\n",
    ")\n",
    "\n",
    "momy = momy_no_res + (df.duvdx_fd + df.duvdy_fd)\n",
    "\n",
    "momy_no_res.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momy_no_res.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how large the Reynold's stress residual is at different locations\n",
    "df1 = df.dropna().reset_index()\n",
    "df1.plot.scatter(\n",
    "    x=\"x\", y=\"y\", color=momy_no_res.dropna().values, cmap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute terms from averaged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the time-averaged profiles\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_profiles():\n",
    "    \"\"\"Read profile data from JHTDB HDF5 file, and assemble into a dictionary\n",
    "    of NumPy arrays.\n",
    "    \"\"\"\n",
    "    with h5py.File(\n",
    "        \"data/jhtdb-transitional-bl/time-ave-profiles.h5\", \"r\"\n",
    "    ) as f:\n",
    "        data = {}\n",
    "        for k in f.keys():\n",
    "            kn = k.split(\"_\")[0]\n",
    "            if kn.endswith(\"m\"):\n",
    "                kn = kn[:-1]\n",
    "            data[kn] = f[k][()]\n",
    "    # Calculate some finite difference gradients\n",
    "    dx = np.gradient(data[\"x\"])\n",
    "    dy = np.reshape(np.gradient(data[\"y\"]), (224, 1))\n",
    "    # dz = np.gradient(data[\"z\"])\n",
    "    # Correct fluctuation terms according to README\n",
    "    # >uum is the time-averaged of u*u (not u'*u', where u'=u-um).\n",
    "    # >So time-averaged of u'*u'=uum-um*um. Same for other quantities.\n",
    "    for dim1 in (\"u\", \"v\", \"w\"):\n",
    "        for dim2 in (\"u\", \"v\", \"w\"):\n",
    "            if f\"{dim1}{dim2}\" in data:\n",
    "                data[f\"{dim1}{dim2}\"] = (\n",
    "                    data[f\"{dim1}{dim2}\"] - data[dim1] * data[dim2]\n",
    "                )\n",
    "    # Calculate gradients\n",
    "    data[\"dpdx\"] = np.gradient(data[\"p\"], axis=1) / dx\n",
    "    data[\"duudx\"] = np.gradient(data[\"uu\"], axis=1) / dx\n",
    "    data[\"duvdx\"] = np.gradient(data[\"uv\"], axis=1) / dx\n",
    "    data[\"duvdy\"] = np.gradient(data[\"uv\"], axis=0) / dy\n",
    "    data[\"dvvdy\"] = np.gradient(data[\"vv\"], axis=0) / dy\n",
    "    data[\"dudx\"] = np.gradient(data[\"u\"], axis=1) / dx\n",
    "    data[\"dudy\"] = np.gradient(data[\"u\"], axis=0) / dy\n",
    "    data[\"dvdx\"] = np.gradient(data[\"v\"], axis=1) / dx\n",
    "    data[\"dvdy\"] = np.gradient(data[\"v\"], axis=0) / dy\n",
    "    data[\"d2udx2\"] = np.gradient(data[\"dudx\"], axis=1) / dx\n",
    "    data[\"d2udy2\"] = np.gradient(data[\"dudy\"], axis=0) / dy\n",
    "    data[\"d2vdx2\"] = np.gradient(data[\"dvdx\"], axis=1) / dx\n",
    "    data[\"d2vdy2\"] = np.gradient(data[\"dvdy\"], axis=0) / dy\n",
    "    data[\"dpdx\"] = np.gradient(data[\"p\"], axis=1) / dx\n",
    "    data[\"dpdy\"] = np.gradient(data[\"p\"], axis=0) / dy\n",
    "    # data[\"dwdz\"] = np.gradient(data[\"w\"], axis=1) / dz\n",
    "    return data\n",
    "\n",
    "\n",
    "data = read_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RANS simulation versus averaged DNS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"k-epsilon\"\n",
    "\n",
    "for ny in [15, 20, 30, 40, 60]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"laminar\"\n",
    "\n",
    "for ny in [40]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Workaround to show LaTeX labels\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(\n",
    "    HTML(\n",
    "        '<script type=\"text/javascript\" async '\n",
    "        'src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/'\n",
    "        '2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.line(x=data[\"u\"][:, 1500], y=data[\"y\"], height=800).update_traces(\n",
    "    line_color=\"green\", line_dash=\"dash\", name=\"DNS\"\n",
    ")\n",
    "\n",
    "turbulence_model = \"new\"\n",
    "\n",
    "for ny in [40]:\n",
    "    fpaths = glob.glob(\n",
    "        f\"sim/cases/{turbulence_model}-ny-{ny}/\"\n",
    "        \"postProcessing/sample/*/x906.8_U.csv\"\n",
    "    )\n",
    "    assert len(fpaths) == 1\n",
    "    df2 = pd.read_csv(fpaths[0])\n",
    "    fig2 = df2.plot(x=\"U_0\", y=\"y\", backend=\"plotly\").update_traces(\n",
    "        name=f\"$N_y = {ny}$\"\n",
    "    )\n",
    "    fig = fig.add_trace(fig2.data[0])\n",
    "    fig.data[0].name = \"DNS\"\n",
    "    fig.data[1].name = r\"$k$--$\\epsilon$\"\n",
    "fig = fig.update_layout(\n",
    "    showlegend=True, xaxis=dict(title=r\"$U$\"), yaxis=dict(title=\"$y$\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=-nu * data[\"d2udy2\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=1 / rho * data[\"dpdx\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=data[\"dudy\"][:, 1500], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = (\n",
    "    px.line(x=data[\"dudy\"][:, 1500]**(3)*data[\"y\"], y=data[\"y\"], height=800)\n",
    "    .update_traces(line_color=\"green\", line_dash=\"dash\", name=\"DNS\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect coefficients of new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a bunch of quantities and add to the data\n",
    "data = read_profiles()\n",
    "dx = np.gradient(data[\"x\"])\n",
    "dy = np.reshape(np.gradient(data[\"y\"]), (224, 1))\n",
    "# Advection of momentum\n",
    "data[\"advection_x\"] = data[\"u\"] * data[\"dudx\"] + data[\"v\"] * data[\"dudy\"]\n",
    "data[\"advection_y\"] = data[\"u\"] * data[\"dvdx\"] + data[\"v\"] * data[\"dvdy\"]\n",
    "# Mean kinetic energy\n",
    "data[\"k\"] = 0.5 * (data[\"u\"] ** 2 + data[\"v\"] ** 2)\n",
    "# Squared gradients\n",
    "data[\"dudx2\"] = data[\"dudx\"] ** 2\n",
    "data[\"dudy2\"] = data[\"dudy\"] ** 2\n",
    "# Gradients of squares\n",
    "data[\"du2dy\"] = np.gradient(data[\"u\"] ** 2, axis=0) / dy\n",
    "data[\"dv2dy\"] = np.gradient(data[\"v\"] ** 2, axis=0) / dy\n",
    "data[\"du2dx\"] = np.gradient(data[\"u\"] ** 2, axis=1) / dx\n",
    "data[\"dv2dx\"] = np.gradient(data[\"v\"] ** 2, axis=1) / dx\n",
    "# Mean kinetic energy gradient\n",
    "data[\"dkdy\"] = np.gradient(data[\"k\"], axis=0) / dy\n",
    "data[\"dkdx\"] = np.gradient(data[\"k\"], axis=1) / dx\n",
    "data[\"d2kdy2\"] = np.gradient(data[\"dkdy\"], axis=0) / dy\n",
    "data[\"d2kdx2\"] = np.gradient(data[\"dkdx\"], axis=1) / dx\n",
    "# Gradients multiplied by each other\n",
    "# Gradients multiplied by mean values\n",
    "# Misc terms\n",
    "data[\"u2dudy\"] = data[\"u\"] ** 2 * data[\"dudy\"]\n",
    "data[\"udpdx\"] = data[\"u\"] * data[\"dpdx\"]\n",
    "data[\"dpdx2\"] = data[\"dpdx\"] ** 2\n",
    "data[\"dpdy2\"] = data[\"dpdy\"] ** 2\n",
    "data[\"d2pdx2\"] = np.gradient(data[\"dpdx\"], axis=1) / dx\n",
    "data[\"d2pdy2\"] = np.gradient(data[\"dpdy\"], axis=0) / dy\n",
    "data[\"dp2dx\"] = np.gradient(data[\"p\"] ** 2, axis=1) / dx\n",
    "data[\"dp2dy\"] = np.gradient(data[\"p\"] ** 2, axis=0) / dy\n",
    "data[\"vdpdy\"] = data[\"v\"] * data[\"dpdy\"]\n",
    "data[\"duudy\"] = np.gradient(data[\"uu\"], axis=0) / dy\n",
    "data[\"magsqrgradp\"] = data[\"dpdx\"] ** 2 + data[\"dpdy\"] ** 2\n",
    "data[\"laplacianp\"] = data[\"d2pdx2\"] + data[\"d2pdy2\"]\n",
    "data[\"laplacianvel_x\"] = data[\"d2udx2\"] + data[\"d2udy2\"]\n",
    "data[\"laplacianvel_y\"] = data[\"d2vdx2\"] + data[\"d2vdy2\"]\n",
    "data[\"vorticityz\"] = data[\"dvdx\"] - data[\"dudy\"]\n",
    "data[\"gradmagvort_x\"] = np.gradient(data[\"vorticityz\"], axis=1) / dx\n",
    "data[\"gradmagvort_y\"] = np.gradient(data[\"vorticityz\"], axis=0) / dy\n",
    "data[\"pu\"] = data[\"p\"] * data[\"u\"]\n",
    "data[\"pv\"] = data[\"p\"] * data[\"v\"]\n",
    "data[\"divvelpgrad_x\"] = data[\"u\"] * data[\"d2pdx2\"] + data[\"u\"] * data[\"d2pdy2\"]\n",
    "data[\"divvelpgrad_y\"] = data[\"v\"] * data[\"d2pdx2\"] + data[\"v\"] * data[\"d2pdy2\"]\n",
    "data[\"duvdy\"] = np.gradient(data[\"uv\"], axis=0) / dy\n",
    "data[\"duvdx\"] = np.gradient(data[\"uv\"], axis=1) / dx\n",
    "data[\"divuu_x\"] = data[\"du2dx\"] + data[\"duvdy\"]\n",
    "data[\"divuu_y\"] = data[\"duvdx\"] + data[\"dv2dy\"]\n",
    "data[\"magsqru\"] = data[\"u\"] ** 2 + data[\"v\"] ** 2\n",
    "data[\"pbymagsqru\"] = data[\"p\"] / data[\"magsqru\"]\n",
    "data[\"gradpbymagsqru_x\"] = np.gradient(data[\"pbymagsqru\"], axis=1) / dx\n",
    "data[\"gradpbymagsqru_y\"] = np.gradient(data[\"pbymagsqru\"], axis=0) / dy\n",
    "data[\"divp\"] = data[\"dpdx\"] + data[\"dpdy\"]\n",
    "data[\"ddivpdx\"] = np.gradient(data[\"divp\"], axis=1) / dx\n",
    "data[\"ddivpdy\"] = np.gradient(data[\"divp\"], axis=0) / dy\n",
    "data[\"gradugradpx\"] = data[\"dudx\"] * data[\"dpdx\"] + data[\"dudy\"] * data[\"dpdy\"]\n",
    "data[\"gradugradpy\"] = data[\"dvdx\"] * data[\"dpdx\"] + data[\"dvdy\"] * data[\"dpdy\"]\n",
    "# Reynolds stress terms\n",
    "data[\"restress_x\"] = data[\"duudx\"] + data[\"duvdy\"]\n",
    "data[\"restress_y\"] = data[\"duvdx\"] + data[\"dvvdy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_package.plotting import plot_heatmap\n",
    "\n",
    "plot_heatmap(\n",
    "    data[\"uu\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_package.plotting import plot_heatmap\n",
    "\n",
    "plot_heatmap(\n",
    "    data[\"uv\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_package.plotting import plot_heatmap\n",
    "\n",
    "plot_heatmap(\n",
    "    data[\"vv\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"restress_y\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"u\"] * data[\"dpdy\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"duvdy\"],\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    -(data[\"dkdx\"] + data[\"dkdy\"])**2,\n",
    "    data,\n",
    "    interactive=False,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "terms = [\n",
    "    # Mean kinetic energy gradients\n",
    "    \"dkdx\",\n",
    "    # \"dkdy\",\n",
    "    # Squared velocity gradients\n",
    "    # \"dudx2\",\n",
    "    # \"dudy2\",\n",
    "    # Gradients of squared velocity\n",
    "    # \"du2dx\",\n",
    "    # \"du2dy\",\n",
    "    # \"dv2dx\",\n",
    "    # \"dv2dy\",\n",
    "    # Cross-stream pressure gradient\n",
    "    # \"dpdy\",\n",
    "    # Misc\n",
    "    # \"u2dudy\",\n",
    "    # \"udpdx\",\n",
    "    # \"dpdx2\",\n",
    "    \"dpdy2\",\n",
    "    \"d2pdx2\",\n",
    "    \"d2pdy2\",\n",
    "    # \"dp2dx\",\n",
    "    # \"dpdx\",\n",
    "]\n",
    "\n",
    "# Form our X matrix\n",
    "X = np.array([data[term].flatten() for term in terms]).transpose()\n",
    "\n",
    "# Form our y vector, which is simply the x-component of the 2-D RANS equations\n",
    "# with no Reynolds stresses\n",
    "y = (\n",
    "    data[\"u\"] * data[\"dudx\"]\n",
    "    + data[\"v\"] * data[\"dudy\"]\n",
    "    + 1 / rho * data[\"dpdx\"]\n",
    "    - nu * (data[\"d2udx2\"] + data[\"d2udy2\"])\n",
    ").flatten()\n",
    "\n",
    "print(\"Dataset size:\", len(y))\n",
    "\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "terms = [\n",
    "    # Mean kinetic energy gradients\n",
    "    # \"dkdx\",\n",
    "    \"dkdy\",\n",
    "    # Squared velocity gradients\n",
    "    # \"dudx2\",\n",
    "    # \"dudy2\",\n",
    "    # Gradients of squared velocity\n",
    "    # \"du2dx\",\n",
    "    # \"du2dy\",\n",
    "    # \"dv2dx\",\n",
    "    # \"dv2dy\",\n",
    "    # Streamwise pressure gradient\n",
    "    # \"dpdx\",\n",
    "    # Misc\n",
    "    # \"u2dudy\",\n",
    "    # \"udpdx\",\n",
    "    \"dpdx2\",\n",
    "    \"dpdy2\",\n",
    "    # \"d2pdx2\",\n",
    "    \"d2pdx2\",\n",
    "    \"d2pdy2\",\n",
    "    # \"dp2dx\",\n",
    "    # \"dpdy\",\n",
    "]\n",
    "\n",
    "# Form our X matrix\n",
    "X = np.array([data[term].flatten() for term in terms]).transpose()\n",
    "\n",
    "# Form our y vector, which is simply the x-component of the 2-D RANS equations\n",
    "# with no Reynolds stresses\n",
    "y = (\n",
    "    data[\"u\"] * data[\"dvdx\"]\n",
    "    + data[\"v\"] * data[\"dvdy\"]\n",
    "    + 1 / rho * data[\"dpdy\"]\n",
    "    - nu * (data[\"d2vdx2\"] + data[\"d2vdy2\"])\n",
    ").flatten()\n",
    "print(\"Dataset size:\", len(y))\n",
    "\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Now we need to solve for both components at the same time so we use the same\n",
    "# parameters for each\n",
    "terms = [\n",
    "    # \"dkd{dim}\",\n",
    "    \"gradugradp{dim}\",\n",
    "    # \"restress_{dim}\",  # Should be the most important term, but cheating\n",
    "    \"divuu_{dim}\",\n",
    "    \"divvelpgrad_{dim}\",\n",
    "    \"ddivpd{dim}\",\n",
    "    \"gradpbymagsqru_{dim}\",\n",
    "    # \"advection_{dim}\",\n",
    "    # \"dpd{dim}\",  # Cheating?\n",
    "    # \"laplacianvel_{dim}\",  # Cheating?\n",
    "]\n",
    "xterms = [t.format(dim=\"x\") for t in terms]\n",
    "yterms = [t.format(dim=\"y\") for t in terms]\n",
    "\n",
    "# Slice out \"non-important\" parts of the flow to not train on those\n",
    "# Basically that means stay near the wall and away from the inlet\n",
    "ix_min = 500\n",
    "iy_max = 100\n",
    "\n",
    "# Form our X matrix\n",
    "xx = np.array([data[term].flatten() for term in xterms]).transpose()\n",
    "xy = np.array([data[term].flatten() for term in yterms]).transpose()\n",
    "X = np.concatenate([xx, xy])\n",
    "xx_slice = np.array(\n",
    "    [data[term][:iy_max, ix_min:].flatten() for term in xterms]\n",
    ").transpose()\n",
    "xy_slice = np.array(\n",
    "    [data[term][:iy_max, ix_min:].flatten() for term in yterms]\n",
    ").transpose()\n",
    "X_slice = np.concatenate([xx_slice, xy_slice])\n",
    "\n",
    "xtarget = (\n",
    "    data[\"u\"] * data[\"dudx\"]\n",
    "    + data[\"v\"] * data[\"dudy\"]\n",
    "    + 1 / rho * data[\"dpdx\"]\n",
    "    - nu * (data[\"d2udx2\"] + data[\"d2udy2\"])\n",
    ")\n",
    "ytarget = (\n",
    "    data[\"u\"] * data[\"dvdx\"]\n",
    "    + data[\"v\"] * data[\"dvdy\"]\n",
    "    + 1 / rho * data[\"dpdy\"]\n",
    "    - nu * (data[\"d2vdx2\"] + data[\"d2vdy2\"])\n",
    ")\n",
    "xtarget = data[\"restress_x\"]\n",
    "ytarget = data[\"restress_y\"]\n",
    "# xtarget = np.zeros(data[\"u\"].shape)\n",
    "# ytarget = np.zeros(data[\"v\"].shape)\n",
    "\n",
    "# Our y vector is both of these appended to each other\n",
    "y = np.concatenate([xtarget.flatten(), ytarget.flatten()])\n",
    "y_slice = np.concatenate(\n",
    "    [xtarget[:iy_max, ix_min:].flatten(), ytarget[:iy_max, ix_min:].flatten()]\n",
    ")\n",
    "print(\"Dataset size:\", len(y_slice))\n",
    "\n",
    "# Fit the model\n",
    "reg = LinearRegression(fit_intercept=False).fit(X_slice, y_slice)\n",
    "\n",
    "# Compute the RMSE of the fit\n",
    "rmse_no_model = np.sqrt(np.sum(y**2))\n",
    "pred = reg.predict(X)\n",
    "error = y - pred\n",
    "rmse_model = np.sqrt(np.sum(error**2))\n",
    "error_x = error[: len(error) // 2].reshape((len(data[\"y\"]), len(data[\"x\"])))\n",
    "error_y = error[len(error) // 2 :].reshape((len(data[\"y\"]), len(data[\"x\"])))\n",
    "\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print(\"RMSE no model:\", rmse_no_model)\n",
    "print(\"RMSE model:\", rmse_model)\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The null space approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    \"dkd{dim}\",\n",
    "    # \"gradugradp{dim}\",\n",
    "    # \"restress_{dim}\",\n",
    "    # \"divuu_{dim}\",\n",
    "    # \"divvelpgrad_{dim}\",\n",
    "    \"ddivpd{dim}\",\n",
    "    \"gradpbymagsqru_{dim}\",\n",
    "    \"advection_{dim}\",\n",
    "    \"dpd{dim}\",\n",
    "    \"laplacianvel_{dim}\",\n",
    "]\n",
    "\n",
    "# The RHS of our system of equations?\n",
    "# J =\n",
    "xi_min = 600\n",
    "yi_max = 100\n",
    "\n",
    "\n",
    "def nullspace(A, eps=1e-15):\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    null_space = np.compress(s <= eps, vh, axis=0)\n",
    "    return null_space.T\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "all_coeffs = []\n",
    "\n",
    "for _ in range(iterations):\n",
    "    K = np.zeros((len(terms), len(terms)))\n",
    "    for n in range(len(terms)):\n",
    "        # Pick random indices\n",
    "        xi = np.random.choice(np.arange(len(data[\"x\"]))[xi_min:])\n",
    "        yi = np.random.choice(np.arange(len(data[\"y\"]))[:yi_max])\n",
    "        for m, term in enumerate(terms):\n",
    "            K[n, m] = (\n",
    "                data[term.format(dim=\"x\")][yi, xi]\n",
    "                - data[term.format(dim=\"y\")][yi, xi]\n",
    "            )\n",
    "    try:\n",
    "        M = nullspace(K, eps=1e-4)\n",
    "        coeffs = (M.T/M[0])[0]\n",
    "        # coeffs /= np.max(np.abs(coeffs))\n",
    "        all_coeffs.append(coeffs)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "all_coeffs = np.asarray(all_coeffs)\n",
    "df = pd.DataFrame(all_coeffs, columns=terms)\n",
    "dfm = df.mean()\n",
    "dfm / dfm.abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the distribution of errors coming from the model\n",
    "import py_package.plotting\n",
    "from py_package.plotting import plot_heatmap\n",
    "\n",
    "plot_heatmap(\n",
    "    error_x,\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=True,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"dkdx\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=True,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"duvdy\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=False,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to model the (1, 2) component of the Reynolds stress transport\n",
    "\n",
    "From the inspections above, the cross-stream gradient of \n",
    "$\\overline{u^\\prime v^\\prime}$ is the largest driver of momentum transport\n",
    "in the streamwise direction.\n",
    "Therefore, we should try to find a PDE that describes this field well,\n",
    "such that we can solve that and plug it back into the momentum\n",
    "equation.\n",
    "\n",
    "We could use something like\n",
    "\n",
    "$$\n",
    "\\left( \n",
    "    \\nabla \\cdot \\vec{U}\n",
    "\\right) \\mathbf{R}\n",
    "=\n",
    "  a \\nabla^2 \\mathbf{R}\n",
    "+ b \\vec{U} \\nabla P\n",
    "+ c \\nabla \\vec{U}\n",
    "+ d \\vec{U} \\nabla K\n",
    "+ e \\nabla P \\nabla P\n",
    "$$\n",
    "\n",
    "for which the (1, 2) component is\n",
    "\n",
    "$$\n",
    "  U \\frac{\\partial \\overline{u^\\prime v^\\prime}}{\\partial x}\n",
    "+ V \\frac{\\partial \\overline{u^\\prime v^\\prime}}{\\partial y}\n",
    "=\n",
    "  a \\left( \n",
    "    \\frac{\\partial^2 \\overline{u^\\prime v^\\prime}}{\\partial x^2} \n",
    "    + \\frac{\\partial^2 \\overline{u^\\prime v^\\prime}}{\\partial y^2} \n",
    "  \\right)\n",
    "+ b U \\frac{\\partial P}{\\partial y}\n",
    "+ c \\frac{\\partial U}{\\partial y}\n",
    "+ d U \\frac{\\partial K}{\\partial y}\n",
    "+ e \\frac{\\partial P}{\\partial x} \\frac{\\partial P}{\\partial y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a bunch of quantities and add to the data\n",
    "data = read_profiles()\n",
    "dx = np.gradient(data[\"x\"])\n",
    "dy = np.reshape(np.gradient(data[\"y\"]), (224, 1))\n",
    "data[\"k\"] = 0.5 * (data[\"u\"] ** 2 + data[\"v\"] ** 2)\n",
    "data[\"dkdy\"] = np.gradient(data[\"k\"], axis=0) / dy\n",
    "data[\"dpdx\"] = np.gradient(data[\"p\"], axis=1) / dx\n",
    "data[\"dpdy\"] = np.gradient(data[\"p\"], axis=0) / dy\n",
    "data[\"duvdx\"] = np.gradient(data[\"uv\"], axis=1) / dx\n",
    "data[\"duvdy\"] = np.gradient(data[\"uv\"], axis=0) / dy\n",
    "data[\"d2uvdx2\"] = np.gradient(data[\"duvdx\"], axis=1) / dx\n",
    "data[\"d2uvdy2\"] = np.gradient(data[\"duvdy\"], axis=0) / dy\n",
    "data[\"adv_uv_12\"] = data[\"u\"] * data[\"duvdx\"] + data[\"v\"] * data[\"duvdy\"]\n",
    "data[\"laplacian_uv_12\"] = data[\"d2uvdx2\"] + data[\"d2uvdy2\"]\n",
    "data[\"u_gradp_12\"] = data[\"u\"] * data[\"dpdy\"]\n",
    "data[\"u_gradk_12\"] = data[\"u\"] * data[\"dkdy\"]\n",
    "data[\"gradp_gradp_12\"] = data[\"dpdx\"] * data[\"dpdy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "terms = [\n",
    "    \"laplacian_uv_12\",\n",
    "    \"u_gradp_12\",\n",
    "    \"dudy\",\n",
    "    \"u_gradk_12\",\n",
    "    # \"gradp_gradp_12\",\n",
    "]\n",
    "# Form our X matrix\n",
    "X = np.array([data[term].flatten() for term in terms]).transpose()\n",
    "# Form our y vector, which is the advection term for uv\n",
    "y = data[\"adv_uv_12\"].flatten()\n",
    "# Fit the model\n",
    "reg = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "# Compute the RMSE of the fit\n",
    "rmse_no_model = np.sqrt(np.sum(y**2))\n",
    "pred = reg.predict(X)\n",
    "error = y - pred\n",
    "rmse_model = np.sqrt(np.sum(error**2))\n",
    "error = error.reshape((len(data[\"y\"]), len(data[\"x\"])))\n",
    "# Print metrics\n",
    "print(\"Score:\", reg.score(X, y))\n",
    "print(\"RMSE no model:\", rmse_no_model)\n",
    "print(\"RMSE model:\", rmse_model)\n",
    "print()\n",
    "for term, coeff in zip(terms, reg.coef_):\n",
    "    print(term, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"duvdy\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=True,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"gradp_gradp_12\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=True,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"u_gradk_12\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=False,\n",
    "    interactive=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    data[\"dudy\"],\n",
    "    data,\n",
    "    ix_min=600,\n",
    "    iy_max=100,\n",
    "    diverging=False,\n",
    "    interactive=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "bl-turb-mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
